{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAUCIE\n",
    "*Sparse Autoencoders for Unsupervised Clustering, Imputation, and Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import plotting\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import saucie\n",
    "import saucie_utils as utils\n",
    "\n",
    "from collections import OrderedDict\n",
    "from saucie import Saucie\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input_dim', 784)\n",
      "('encoder_layers', [1024, 512, 256])\n",
      "('emb_dim', 2)\n",
      "('act_fn', 'tanh')\n",
      "('d_act_fn', 'tanh')\n",
      "('use_bias', True)\n",
      "('loss_fn', 'bce')\n",
      "('opt_method', 'adam')\n",
      "('lr', 0.001)\n",
      "('batch_norm', True)\n",
      "('sparse_config', SparseLayerConfig(id_lam=[100.0, 0.0, 0.0],l1_lam=[0.0, 0.0, 0.0]))\n",
      "('save_path', './saucie_models/mnist')\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data/krishnan/mnist/mnist_data.npz'\n",
    "dataset = 'mnist'\n",
    "data = utils.load_dataset(dataset, data_path)\n",
    "\n",
    "config = saucie.default_config(dataset)\n",
    "print('\\n'.join([str(x) for x in config.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TRAINING FLAGS\n",
    "batch_size = 100     # size of batch during training\n",
    "num_epochs = 20      # number of epochs to train\n",
    "patience = 5         # number of epochs to train without improvement, early stopping\n",
    "log_every = 100      # training loss logging frequency\n",
    "save_every = 200     # checkpointing frequency\n",
    "tb_graph = True      # logs graph to TensorBoard if True\n",
    "tb_summs = True      # logs summaries to TensorBoard if True\n",
    "debug = False        # enable tfdebug\n",
    "verbose = False      # will log in debug mode if True\n",
    "gpu_mem = 0.45       # percent of gpu mem to allocate\n",
    "\n",
    "# PLOTTING FLAGS\n",
    "thresh = .5          # threshold to binarize id regularized layers\n",
    "save_plots = False    # saves plots if True\n",
    "\n",
    "plot_dir = model.save_path + '/plots'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Methods\n",
    "Edit this to change what is saved, printed, trained, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, sess, data, batch_size, num_steps, thresh=0.5, patience=None,\n",
    "          log_freq=100, ckpt_freq=100, save_plots=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Saucie instance to train\n",
    "        sess: tf.Session object to run all ops with\n",
    "        data: utils.DataSet object to load batches and test data from\n",
    "        batch_size: size of batches to train with\n",
    "        num_steps: number of optimizer iteration steps\n",
    "        thresh: threshold for binarization\n",
    "        patience: number of epochs of training allowed without improvement\n",
    "        log_freq: number of steps before printing training loss\n",
    "        ckpt_freq: number of steps before checkpointing model\n",
    "        save_plots: boolean determining whether or not to save plots\n",
    "    \"\"\"\n",
    "    model.epochs_trained = data.epochs_trained = model.current_epoch_.eval(sess)\n",
    "    graph = sess.graph\n",
    "    loss_tensors = model.loss_tensors_dict(graph)\n",
    "    train_ops = dict(losses=loss_tensors, opt=model.optimize)\n",
    "    test_ops = dict(losses=loss_tensors)\n",
    "    test_feed_dict = {model.x_: data.test_data, model.is_training_: False}\n",
    "    train_feed_dict = {model.x_: data.data, model.is_training_: False}\n",
    "    best_test_losses = None\n",
    "    epochs_since_improved = 0\n",
    "    current_step = model.global_step_.eval(sess)\n",
    "    id_lam = model._model_config['sparse_config'].id_lam\n",
    "    l1_lam = model._model_config['sparse_config'].l1_lam\n",
    "    cluster_layers = id_lam.nonzero()[0].tolist()\n",
    "\n",
    "    print('Saving all run data to: {}'.format(model.save_path))\n",
    "\n",
    "    if tb_graph or tb_summs: \n",
    "        train_writer = tf.summary.FileWriter(model.save_path + '/logs/train', graph=graph)\n",
    "        test_writer = tf.summary.FileWriter(model.save_path + '/logs/test', graph=graph)\n",
    "        tf.logging.debug('Saving graph to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if tb_summs:\n",
    "        loss_summs = [tf.summary.scalar(name, loss) for name, loss in loss_tensors.items() if type(loss) != list]\n",
    "        loss_summs = tf.summary.merge(loss_summs)\n",
    "        train_ops['loss_summs'] = loss_summs\n",
    "        test_ops['loss_summs'] = loss_summs\n",
    "        tf.logging.debug('Saving loss summaries to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if save_plots:\n",
    "        plot_folder = model.save_path + '/plots'\n",
    "        if not os.path.exists(plot_folder):\n",
    "            os.makedirs(plot_folder)\n",
    "        plot_ops = OrderedDict(emb=model.encoder)\n",
    "        plot_ops['cluster_acts'] = tf.get_collection('id_normalized_activations')\n",
    "\n",
    "    for step in range(current_step + 1, num_steps + 1):\n",
    "        batch = data.next_batch(batch_size)\n",
    "        if data.labeled:\n",
    "            batch, labels = batch\n",
    "        feed_dict = {model.x_: batch, model.is_training_: True}\n",
    "        train_dict = sess.run(train_ops, feed_dict=feed_dict)\n",
    "        train_losses = train_dict['losses']\n",
    "        if 'loss_summs' in train_dict:\n",
    "            summ = train_dict['loss_summs']\n",
    "            train_writer.add_summary(summ, step)\n",
    "        log_str = ('epoch/step: {}/{}, '.format(model.epochs_trained, step)\n",
    "                   + utils.make_dict_str(train_losses))\n",
    "        tf.logging.log_every_n(tf.logging.INFO, log_str, log_freq)\n",
    "\n",
    "        if ckpt_freq and (step % ckpt_freq) == 0:\n",
    "            tf.logging.info('Saving model, after step {}'.format(step))\n",
    "            model.save_model(sess, 'model', step=step)\n",
    "            if save_plots:\n",
    "                tf.logging.debug('Plotting middle layer embedding')\n",
    "                plot_dict = sess.run(plot_ops, feed_dict=feed_dict)\n",
    "                make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'cluster_layer-{}.png')\n",
    "\n",
    "        if model.epochs_trained != data.epochs_trained:\n",
    "            model.epochs_trained = sess.run(tf.assign(model.current_epoch_, data.epochs_trained))\n",
    "            test_dict = sess.run(test_ops, feed_dict=test_feed_dict)\n",
    "            test_losses = test_dict['losses']\n",
    "            if 'loss_summs' in test_dict:\n",
    "                summ = test_dict['loss_summs']\n",
    "                test_writer.add_summary(summ, step)\n",
    "            log_str = ('TESTING -- epoch: {}, '.format(model.epochs_trained)\n",
    "                       + utils.make_dict_str(test_losses))\n",
    "            tf.logging.info(log_str)\n",
    "            if best_test_losses is None or best_test_losses['loss'] > test_losses['loss']:\n",
    "                model.saver.save(sess, model.save_path + '/best.model')\n",
    "                tf.logging.info('Best model saved after {} epochs'.format(model.epochs_trained))\n",
    "                best_test_losses = test_losses\n",
    "                epochs_since_improved = 0\n",
    "                if save_plots:\n",
    "                    tf.logging.debug('Plotting best middle layer embedding')\n",
    "                    plot_dict = sess.run(plot_ops, feed_dict=test_feed_dict)\n",
    "                    make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'best-cluster_layer-{}.png')\n",
    "            else:\n",
    "                epochs_since_improved += 1\n",
    "            if patience and epochs_since_improved == patience:\n",
    "                tf.logging.info('Early stopping, test loss did not improve for {} epochs.'.format(epochs_since_improved))\n",
    "                tf.logging.info('Best test loss: epoch {}: '.format(model.epochs_trained - epochs_since_improved)\n",
    "                                + utils.make_dict_str(best_test_losses))\n",
    "                break\n",
    "\n",
    "    tf.logging.info('Trained for {} epochs'.format(model.epochs_trained))\n",
    "\n",
    "    print('Saved all run data to: {}'.format(model.save_path))\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "def make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, title_fmt='clust_layer-{}.png'):\n",
    "    for i, acts in enumerate(plot_dict['cluster_acts']):\n",
    "        hl_idx = cluster_layers[i]\n",
    "        save_file = plot_folder + '/emb-' + title_fmt.format(hl_idx)\n",
    "        title = 'Embedding, clustered layer-{}, id_lam/l1_lam={:5.4E}/{:5.4E}'.format(hl_idx, id_lam[hl_idx], l1_lam[hl_idx])\n",
    "        clusts = utils.binarize(acts, thresh)\n",
    "        tf.logging.debug('Top 5 activated neurons: {}'.format(acts.max(axis=1)[:5]))\n",
    "        tf.logging.debug('Mean max activation: {}'.format(acts.max(axis=1).mean()))\n",
    "        tf.logging.debug('Bottom 5 max activated neurons: {}'.format(acts.max(axis=1)[-5:]))\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], clusts, save_file, title)\n",
    "        if '_colnames' in data.__dict__:\n",
    "            save_file = plot_folder + '/heatmap-' + title_fmt.format(hl_idx)\n",
    "            plotting.plot_cluster_heatmap(data.test_data, clusts, data._colnames, data._markers, save_file)\n",
    "    if cluster_layers == []:\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], np.zeros(len(plot_dict['emb'])), plot_folder + '/emb.png','Embedding, no clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "else:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "if debug:\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "model.build(sess)\n",
    "\n",
    "steps_per_epoch = data.num_samples // batch_size\n",
    "num_steps = steps_per_epoch * num_epochs\n",
    "train(model, sess, data, batch_size, num_steps, thresh, patience, log_every, save_every, save_plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
