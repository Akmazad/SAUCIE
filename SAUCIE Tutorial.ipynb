{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAUCIE\n",
    "*Sparse Autoencoders for Unsupervised Clustering, Imputation, and Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import plotting\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import saucie\n",
    "import saucie_utils as utils\n",
    "\n",
    "from collections import OrderedDict\n",
    "from saucie import Saucie\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'opt_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-752dddaae54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saucie_models/zika/17-09-26-runs/0/model.config'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaucie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/old/home/krishnan/projects/SAUCIE/saucie.py\u001b[0m in \u001b[0;36mload_model_from_config\u001b[0;34m(dataset, config_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaucie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'opt_method'"
     ]
    }
   ],
   "source": [
    "data_path = '/data/krishnan/zika_data/gated/combined.npz'\n",
    "dataset = 'zika'\n",
    "data = utils.load_dataset(dataset, data_path)\n",
    "config_path = 'saucie_models/zika/17-09-26-runs/0/model.config'\n",
    "model, config = saucie.load_model_from_config(dataset, config_path)\n",
    "print('\\n'.join([str(x) for x in config.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING FLAGS\n",
    "batch_size = 100     # size of batch during training\n",
    "num_epochs = 20      # number of epochs to train\n",
    "patience = 5         # number of epochs to train without improvement, early stopping\n",
    "log_every = 100      # training loss logging frequency\n",
    "save_every = 200     # checkpointing frequency\n",
    "tb_graph = True      # logs graph to TensorBoard if True\n",
    "tb_summs = True      # logs summaries to TensorBoard if True\n",
    "debug = False        # enable tfdebug\n",
    "verbose = False      # will log in debug mode if True\n",
    "gpu_mem = 0.45       # percent of gpu mem to allocate\n",
    "\n",
    "# PLOTTING FLAGS\n",
    "thresh = .5          # threshold to binarize id regularized layers\n",
    "save_plots = False    # saves plots if True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Methods\n",
    "Edit this to change what is saved, printed, trained, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, sess, data, batch_size, num_steps, thresh=0.5, patience=None,\n",
    "          log_freq=100, ckpt_freq=100, save_plots=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Saucie instance to train\n",
    "        sess: tf.Session object to run all ops with\n",
    "        data: utils.DataSet object to load batches and test data from\n",
    "        batch_size: size of batches to train with\n",
    "        num_steps: number of optimizer iteration steps\n",
    "        thresh: threshold for binarization\n",
    "        patience: number of epochs of training allowed without improvement\n",
    "        log_freq: number of steps before printing training loss\n",
    "        ckpt_freq: number of steps before checkpointing model\n",
    "        save_plots: boolean determining whether or not to save plots\n",
    "    \"\"\"\n",
    "    model.epochs_trained = data.epochs_trained = model.current_epoch_.eval(sess)\n",
    "    graph = sess.graph\n",
    "    loss_tensors = model.loss_tensors_dict(graph)\n",
    "    train_ops = dict(losses=loss_tensors, opt=model.optimize)\n",
    "    test_ops = dict(losses=loss_tensors)\n",
    "    test_feed_dict = {model.x_: data.test_data, model.is_training_: False}\n",
    "    train_feed_dict = {model.x_: data.data, model.is_training_: False}\n",
    "    best_test_losses = None\n",
    "    epochs_since_improved = 0\n",
    "    current_step = model.global_step_.eval(sess)\n",
    "    id_lam = model._model_config['sparse_config'].id_lam\n",
    "    l1_lam = model._model_config['sparse_config'].l1_lam\n",
    "    cluster_layers = id_lam.nonzero()[0].tolist()\n",
    "\n",
    "    print('Saving all run data to: {}'.format(model.save_path))\n",
    "\n",
    "    if tb_graph or tb_summs: \n",
    "        train_writer = tf.summary.FileWriter(model.save_path + '/logs/train', graph=graph)\n",
    "        test_writer = tf.summary.FileWriter(model.save_path + '/logs/test', graph=graph)\n",
    "        tf.logging.debug('Saving graph to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if tb_summs:\n",
    "        loss_summs = [tf.summary.scalar(name, loss) for name, loss in loss_tensors.items() if type(loss) != list]\n",
    "        loss_summs = tf.summary.merge(loss_summs)\n",
    "        train_ops['loss_summs'] = loss_summs\n",
    "        test_ops['loss_summs'] = loss_summs\n",
    "        tf.logging.debug('Saving loss summaries to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if save_plots:\n",
    "        plot_folder = model.save_path + '/plots'\n",
    "        if not os.path.exists(plot_folder):\n",
    "            os.makedirs(plot_folder)\n",
    "        plot_ops = OrderedDict(emb=model.encoder)\n",
    "        plot_ops['cluster_acts'] = tf.get_collection('id_normalized_activations')\n",
    "\n",
    "    for step in range(current_step + 1, num_steps + 1):\n",
    "        batch = data.next_batch(batch_size)\n",
    "        if data.labeled:\n",
    "            batch, labels = batch\n",
    "        feed_dict = {model.x_: batch, model.is_training_: True}\n",
    "        train_dict = sess.run(train_ops, feed_dict=feed_dict)\n",
    "        train_losses = train_dict['losses']\n",
    "        if 'loss_summs' in train_dict:\n",
    "            summ = train_dict['loss_summs']\n",
    "            train_writer.add_summary(summ, step)\n",
    "        log_str = ('epoch/step: {}/{}, '.format(model.epochs_trained, step)\n",
    "                   + utils.make_dict_str(train_losses))\n",
    "        tf.logging.log_every_n(tf.logging.INFO, log_str, log_freq)\n",
    "\n",
    "        if ckpt_freq and (step % ckpt_freq) == 0:\n",
    "            tf.logging.info('Saving model, after step {}'.format(step))\n",
    "            model.save_model(sess, 'model', step=step)\n",
    "            if save_plots:\n",
    "                tf.logging.debug('Plotting middle layer embedding')\n",
    "                plot_dict = sess.run(plot_ops, feed_dict=feed_dict)\n",
    "                make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'cluster_layer-{}.png')\n",
    "\n",
    "        if model.epochs_trained != data.epochs_trained:\n",
    "            model.epochs_trained = sess.run(tf.assign(model.current_epoch_, data.epochs_trained))\n",
    "            test_dict = sess.run(test_ops, feed_dict=test_feed_dict)\n",
    "            test_losses = test_dict['losses']\n",
    "            if 'loss_summs' in test_dict:\n",
    "                summ = test_dict['loss_summs']\n",
    "                test_writer.add_summary(summ, step)\n",
    "            log_str = ('TESTING -- epoch: {}, '.format(model.epochs_trained)\n",
    "                       + utils.make_dict_str(test_losses))\n",
    "            tf.logging.info(log_str)\n",
    "            if best_test_losses is None or best_test_losses['loss'] > test_losses['loss']:\n",
    "                model.saver.save(sess, model.save_path + '/best.model')\n",
    "                tf.logging.info('Best model saved after {} epochs'.format(model.epochs_trained))\n",
    "                best_test_losses = test_losses\n",
    "                epochs_since_improved = 0\n",
    "                if save_plots:\n",
    "                    tf.logging.debug('Plotting best middle layer embedding')\n",
    "                    plot_dict = sess.run(plot_ops, feed_dict=test_feed_dict)\n",
    "                    make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'best-cluster_layer-{}.png')\n",
    "            else:\n",
    "                epochs_since_improved += 1\n",
    "            if patience and epochs_since_improved == patience:\n",
    "                tf.logging.info('Early stopping, test loss did not improve for {} epochs.'.format(epochs_since_improved))\n",
    "                tf.logging.info('Best test loss: epoch {}: '.format(model.epochs_trained - epochs_since_improved)\n",
    "                                + utils.make_dict_str(best_test_losses))\n",
    "                break\n",
    "\n",
    "    tf.logging.info('Trained for {} epochs'.format(model.epochs_trained))\n",
    "\n",
    "    print('Saved all run data to: {}'.format(model.save_path))\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "def make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, title_fmt='clust_layer-{}.png'):\n",
    "    for i, acts in enumerate(plot_dict['cluster_acts']):\n",
    "        hl_idx = cluster_layers[i]\n",
    "        save_file = plot_folder + '/emb-' + title_fmt.format(hl_idx)\n",
    "        title = 'Embedding, clustered layer-{}, id_lam/l1_lam={:5.4E}/{:5.4E}'.format(hl_idx, id_lam[hl_idx], l1_lam[hl_idx])\n",
    "        clusts = utils.binarize(acts, thresh)\n",
    "        tf.logging.debug('Top 5 activated neurons: {}'.format(acts.max(axis=1)[:5]))\n",
    "        tf.logging.debug('Mean max activation: {}'.format(acts.max(axis=1).mean()))\n",
    "        tf.logging.debug('Bottom 5 max activated neurons: {}'.format(acts.max(axis=1)[-5:]))\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], clusts, save_file, title)\n",
    "        if '_colnames' in data.__dict__:\n",
    "            save_file = plot_folder + '/heatmap-' + title_fmt.format(hl_idx)\n",
    "            plotting.plot_cluster_heatmap(data.test_data, clusts, data._colnames, data._markers, save_file)\n",
    "    if cluster_layers == []:\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], np.zeros(len(plot_dict['emb'])), plot_folder + '/emb.png','Embedding, no clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving all run data to: ./saucie_models/mnist/17-09-24-runs/1\n",
      "INFO:tensorflow:epoch/step: 0/1, loss: 1.47476, recons_loss: 0.795778, id_loss: 0.678984\n",
      "INFO:tensorflow:epoch/step: 0/101, loss: 0.282465, recons_loss: 0.233635, id_loss: 0.0488292\n",
      "INFO:tensorflow:Saving model, after step 200\n",
      "INFO:tensorflow:epoch/step: 0/201, loss: 0.226997, recons_loss: 0.202185, id_loss: 0.0248121\n",
      "INFO:tensorflow:epoch/step: 0/301, loss: 0.215149, recons_loss: 0.198394, id_loss: 0.0167547\n",
      "INFO:tensorflow:Saving model, after step 400\n",
      "INFO:tensorflow:epoch/step: 0/401, loss: 0.207423, recons_loss: 0.19098, id_loss: 0.016443\n",
      "INFO:tensorflow:epoch/step: 0/501, loss: 0.211424, recons_loss: 0.196827, id_loss: 0.0145967\n",
      "INFO:tensorflow:TESTING -- epoch: 1, loss: 4.7308, recons_loss: 0.287358, id_loss: 4.44344\n",
      "INFO:tensorflow:Best model saved after 1 epochs\n",
      "INFO:tensorflow:Saving model, after step 600\n",
      "INFO:tensorflow:epoch/step: 1/601, loss: 0.210243, recons_loss: 0.197404, id_loss: 0.0128394\n",
      "INFO:tensorflow:epoch/step: 1/701, loss: 0.190706, recons_loss: 0.180354, id_loss: 0.0103527\n",
      "INFO:tensorflow:Saving model, after step 800\n",
      "INFO:tensorflow:epoch/step: 1/801, loss: 0.184569, recons_loss: 0.175221, id_loss: 0.00934871\n",
      "INFO:tensorflow:epoch/step: 1/901, loss: 0.192402, recons_loss: 0.183508, id_loss: 0.00889453\n",
      "INFO:tensorflow:Saving model, after step 1000\n",
      "INFO:tensorflow:epoch/step: 1/1001, loss: 0.191372, recons_loss: 0.183406, id_loss: 0.00796654\n",
      "INFO:tensorflow:epoch/step: 1/1101, loss: 0.2055, recons_loss: 0.197105, id_loss: 0.00839582\n",
      "INFO:tensorflow:TESTING -- epoch: 2, loss: 3.28082, recons_loss: 0.305031, id_loss: 2.97579\n",
      "INFO:tensorflow:Best model saved after 2 epochs\n",
      "INFO:tensorflow:Saving model, after step 1200\n",
      "INFO:tensorflow:epoch/step: 2/1201, loss: 0.201818, recons_loss: 0.189756, id_loss: 0.0120622\n",
      "INFO:tensorflow:epoch/step: 2/1301, loss: 0.200596, recons_loss: 0.190523, id_loss: 0.0100724\n",
      "INFO:tensorflow:Saving model, after step 1400\n",
      "INFO:tensorflow:epoch/step: 2/1401, loss: 0.19413, recons_loss: 0.187631, id_loss: 0.00649936\n",
      "INFO:tensorflow:epoch/step: 2/1501, loss: 0.19955, recons_loss: 0.191203, id_loss: 0.00834754\n",
      "INFO:tensorflow:Saving model, after step 1600\n",
      "INFO:tensorflow:epoch/step: 2/1601, loss: 0.185195, recons_loss: 0.177474, id_loss: 0.00772076\n",
      "INFO:tensorflow:TESTING -- epoch: 3, loss: 2.90345, recons_loss: 0.317341, id_loss: 2.58611\n",
      "INFO:tensorflow:Best model saved after 3 epochs\n",
      "INFO:tensorflow:epoch/step: 3/1701, loss: 0.199624, recons_loss: 0.19283, id_loss: 0.00679383\n",
      "INFO:tensorflow:Saving model, after step 1800\n",
      "INFO:tensorflow:epoch/step: 3/1801, loss: 0.17719, recons_loss: 0.173353, id_loss: 0.00383668\n",
      "INFO:tensorflow:epoch/step: 3/1901, loss: 0.186626, recons_loss: 0.181372, id_loss: 0.00525434\n",
      "INFO:tensorflow:Saving model, after step 2000\n",
      "INFO:tensorflow:epoch/step: 3/2001, loss: 0.190601, recons_loss: 0.184725, id_loss: 0.00587681\n",
      "INFO:tensorflow:epoch/step: 3/2101, loss: 0.187054, recons_loss: 0.183275, id_loss: 0.00377884\n",
      "INFO:tensorflow:Saving model, after step 2200\n",
      "INFO:tensorflow:epoch/step: 3/2201, loss: 0.178707, recons_loss: 0.176293, id_loss: 0.00241347\n",
      "INFO:tensorflow:TESTING -- epoch: 4, loss: 1.93252, recons_loss: 0.322042, id_loss: 1.61048\n",
      "INFO:tensorflow:Best model saved after 4 epochs\n",
      "INFO:tensorflow:epoch/step: 4/2301, loss: 0.182048, recons_loss: 0.178598, id_loss: 0.0034501\n",
      "INFO:tensorflow:Saving model, after step 2400\n",
      "INFO:tensorflow:epoch/step: 4/2401, loss: 0.186649, recons_loss: 0.179817, id_loss: 0.00683133\n",
      "INFO:tensorflow:epoch/step: 4/2501, loss: 0.183328, recons_loss: 0.178297, id_loss: 0.00503045\n",
      "INFO:tensorflow:Saving model, after step 2600\n",
      "INFO:tensorflow:epoch/step: 4/2601, loss: 0.186142, recons_loss: 0.177897, id_loss: 0.0082457\n",
      "INFO:tensorflow:epoch/step: 4/2701, loss: 0.188623, recons_loss: 0.183535, id_loss: 0.00508808\n",
      "INFO:tensorflow:TESTING -- epoch: 5, loss: 1.92467, recons_loss: 0.321645, id_loss: 1.60303\n",
      "INFO:tensorflow:Best model saved after 5 epochs\n",
      "INFO:tensorflow:Saving model, after step 2800\n",
      "INFO:tensorflow:epoch/step: 5/2801, loss: 0.185067, recons_loss: 0.183727, id_loss: 0.00134068\n",
      "INFO:tensorflow:epoch/step: 5/2901, loss: 0.188417, recons_loss: 0.185501, id_loss: 0.00291575\n",
      "INFO:tensorflow:Saving model, after step 3000\n",
      "INFO:tensorflow:epoch/step: 5/3001, loss: 0.181959, recons_loss: 0.174791, id_loss: 0.00716785\n",
      "INFO:tensorflow:epoch/step: 5/3101, loss: 0.18166, recons_loss: 0.178096, id_loss: 0.00356398\n",
      "INFO:tensorflow:Saving model, after step 3200\n",
      "INFO:tensorflow:epoch/step: 5/3201, loss: 0.179281, recons_loss: 0.173881, id_loss: 0.00539955\n",
      "INFO:tensorflow:epoch/step: 5/3301, loss: 0.188414, recons_loss: 0.185149, id_loss: 0.00326474\n",
      "INFO:tensorflow:TESTING -- epoch: 6, loss: 2.13199, recons_loss: 0.32433, id_loss: 1.80765\n",
      "INFO:tensorflow:Saving model, after step 3400\n",
      "INFO:tensorflow:epoch/step: 6/3401, loss: 0.186986, recons_loss: 0.182965, id_loss: 0.00402046\n",
      "INFO:tensorflow:epoch/step: 6/3501, loss: 0.179046, recons_loss: 0.174618, id_loss: 0.00442862\n",
      "INFO:tensorflow:Saving model, after step 3600\n",
      "INFO:tensorflow:epoch/step: 6/3601, loss: 0.191256, recons_loss: 0.186549, id_loss: 0.00470679\n",
      "INFO:tensorflow:epoch/step: 6/3701, loss: 0.189981, recons_loss: 0.186422, id_loss: 0.00355959\n",
      "INFO:tensorflow:Saving model, after step 3800\n",
      "INFO:tensorflow:epoch/step: 6/3801, loss: 0.178602, recons_loss: 0.175196, id_loss: 0.00340633\n",
      "INFO:tensorflow:TESTING -- epoch: 7, loss: 1.72265, recons_loss: 0.33665, id_loss: 1.386\n",
      "INFO:tensorflow:Best model saved after 7 epochs\n",
      "INFO:tensorflow:epoch/step: 7/3901, loss: 0.190447, recons_loss: 0.186341, id_loss: 0.00410588\n",
      "INFO:tensorflow:Saving model, after step 4000\n",
      "INFO:tensorflow:epoch/step: 7/4001, loss: 0.17922, recons_loss: 0.172121, id_loss: 0.0070996\n",
      "INFO:tensorflow:epoch/step: 7/4101, loss: 0.188609, recons_loss: 0.184354, id_loss: 0.00425462\n",
      "INFO:tensorflow:Saving model, after step 4200\n",
      "INFO:tensorflow:epoch/step: 7/4201, loss: 0.182054, recons_loss: 0.178402, id_loss: 0.00365222\n",
      "INFO:tensorflow:epoch/step: 7/4301, loss: 0.183767, recons_loss: 0.17735, id_loss: 0.00641623\n",
      "INFO:tensorflow:Saving model, after step 4400\n",
      "INFO:tensorflow:epoch/step: 7/4401, loss: 0.174566, recons_loss: 0.170231, id_loss: 0.00433442\n",
      "INFO:tensorflow:TESTING -- epoch: 8, loss: 1.57402, recons_loss: 0.333309, id_loss: 1.24071\n",
      "INFO:tensorflow:Best model saved after 8 epochs\n",
      "INFO:tensorflow:epoch/step: 8/4501, loss: 0.177493, recons_loss: 0.173708, id_loss: 0.00378576\n",
      "INFO:tensorflow:Saving model, after step 4600\n",
      "INFO:tensorflow:epoch/step: 8/4601, loss: 0.172253, recons_loss: 0.169782, id_loss: 0.00247107\n",
      "INFO:tensorflow:epoch/step: 8/4701, loss: 0.188814, recons_loss: 0.186442, id_loss: 0.0023717\n",
      "INFO:tensorflow:Saving model, after step 4800\n",
      "INFO:tensorflow:epoch/step: 8/4801, loss: 0.18156, recons_loss: 0.176364, id_loss: 0.00519599\n",
      "INFO:tensorflow:epoch/step: 8/4901, loss: 0.187678, recons_loss: 0.181993, id_loss: 0.00568514\n",
      "INFO:tensorflow:TESTING -- epoch: 9, loss: 1.41315, recons_loss: 0.354742, id_loss: 1.0584\n",
      "INFO:tensorflow:Best model saved after 9 epochs\n",
      "INFO:tensorflow:Saving model, after step 5000\n",
      "INFO:tensorflow:epoch/step: 9/5001, loss: 0.17237, recons_loss: 0.168863, id_loss: 0.0035068\n",
      "INFO:tensorflow:epoch/step: 9/5101, loss: 0.180288, recons_loss: 0.176592, id_loss: 0.003696\n",
      "INFO:tensorflow:Saving model, after step 5200\n",
      "INFO:tensorflow:epoch/step: 9/5201, loss: 0.182548, recons_loss: 0.179442, id_loss: 0.00310634\n",
      "INFO:tensorflow:epoch/step: 9/5301, loss: 0.181894, recons_loss: 0.177859, id_loss: 0.00403538\n",
      "INFO:tensorflow:Saving model, after step 5400\n",
      "INFO:tensorflow:epoch/step: 9/5401, loss: 0.184821, recons_loss: 0.182704, id_loss: 0.00211637\n",
      "INFO:tensorflow:epoch/step: 9/5501, loss: 0.199639, recons_loss: 0.197905, id_loss: 0.00173383\n",
      "INFO:tensorflow:TESTING -- epoch: 10, loss: 1.31977, recons_loss: 0.360309, id_loss: 0.959463\n",
      "INFO:tensorflow:Best model saved after 10 epochs\n",
      "INFO:tensorflow:Saving model, after step 5600\n",
      "INFO:tensorflow:epoch/step: 10/5601, loss: 0.186638, recons_loss: 0.183113, id_loss: 0.00352489\n",
      "INFO:tensorflow:epoch/step: 10/5701, loss: 0.183903, recons_loss: 0.179679, id_loss: 0.00422342\n",
      "INFO:tensorflow:Saving model, after step 5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:epoch/step: 10/5801, loss: 0.192489, recons_loss: 0.190618, id_loss: 0.00187045\n",
      "INFO:tensorflow:epoch/step: 10/5901, loss: 0.186515, recons_loss: 0.184092, id_loss: 0.00242302\n",
      "INFO:tensorflow:Saving model, after step 6000\n",
      "INFO:tensorflow:epoch/step: 10/6001, loss: 0.176138, recons_loss: 0.174788, id_loss: 0.0013493\n",
      "INFO:tensorflow:TESTING -- epoch: 11, loss: 1.2583, recons_loss: 0.381696, id_loss: 0.876602\n",
      "INFO:tensorflow:Best model saved after 11 epochs\n",
      "INFO:tensorflow:epoch/step: 11/6101, loss: 0.17814, recons_loss: 0.174749, id_loss: 0.00339095\n",
      "INFO:tensorflow:Saving model, after step 6200\n",
      "INFO:tensorflow:epoch/step: 11/6201, loss: 0.185492, recons_loss: 0.178528, id_loss: 0.00696445\n",
      "INFO:tensorflow:epoch/step: 11/6301, loss: 0.172362, recons_loss: 0.170685, id_loss: 0.00167715\n",
      "INFO:tensorflow:Saving model, after step 6400\n",
      "INFO:tensorflow:epoch/step: 11/6401, loss: 0.196343, recons_loss: 0.195229, id_loss: 0.00111381\n",
      "INFO:tensorflow:epoch/step: 11/6501, loss: 0.169752, recons_loss: 0.164566, id_loss: 0.00518575\n",
      "INFO:tensorflow:Saving model, after step 6600\n",
      "INFO:tensorflow:epoch/step: 11/6601, loss: 0.169574, recons_loss: 0.16813, id_loss: 0.00144366\n",
      "INFO:tensorflow:TESTING -- epoch: 12, loss: 1.57753, recons_loss: 0.381325, id_loss: 1.19621\n",
      "INFO:tensorflow:epoch/step: 12/6701, loss: 0.179237, recons_loss: 0.174921, id_loss: 0.00431656\n",
      "INFO:tensorflow:Saving model, after step 6800\n",
      "INFO:tensorflow:epoch/step: 12/6801, loss: 0.179945, recons_loss: 0.177116, id_loss: 0.00282883\n",
      "INFO:tensorflow:epoch/step: 12/6901, loss: 0.172254, recons_loss: 0.169503, id_loss: 0.00275114\n",
      "INFO:tensorflow:Saving model, after step 7000\n",
      "INFO:tensorflow:epoch/step: 12/7001, loss: 0.183424, recons_loss: 0.181366, id_loss: 0.00205795\n",
      "INFO:tensorflow:epoch/step: 12/7101, loss: 0.184094, recons_loss: 0.180607, id_loss: 0.00348648\n",
      "INFO:tensorflow:TESTING -- epoch: 13, loss: 1.26342, recons_loss: 0.385373, id_loss: 0.878045\n",
      "INFO:tensorflow:Saving model, after step 7200\n",
      "INFO:tensorflow:epoch/step: 13/7201, loss: 0.177736, recons_loss: 0.174954, id_loss: 0.00278222\n",
      "INFO:tensorflow:epoch/step: 13/7301, loss: 0.181162, recons_loss: 0.178239, id_loss: 0.00292284\n",
      "INFO:tensorflow:Saving model, after step 7400\n",
      "INFO:tensorflow:epoch/step: 13/7401, loss: 0.174173, recons_loss: 0.171363, id_loss: 0.00280922\n",
      "INFO:tensorflow:epoch/step: 13/7501, loss: 0.183728, recons_loss: 0.18222, id_loss: 0.00150786\n",
      "INFO:tensorflow:Saving model, after step 7600\n",
      "INFO:tensorflow:epoch/step: 13/7601, loss: 0.181232, recons_loss: 0.179139, id_loss: 0.00209335\n",
      "INFO:tensorflow:epoch/step: 13/7701, loss: 0.172023, recons_loss: 0.168811, id_loss: 0.00321167\n",
      "INFO:tensorflow:TESTING -- epoch: 14, loss: 1.24003, recons_loss: 0.395332, id_loss: 0.844695\n",
      "INFO:tensorflow:Best model saved after 14 epochs\n",
      "INFO:tensorflow:Saving model, after step 7800\n",
      "INFO:tensorflow:epoch/step: 14/7801, loss: 0.179441, recons_loss: 0.176159, id_loss: 0.00328238\n",
      "INFO:tensorflow:epoch/step: 14/7901, loss: 0.177177, recons_loss: 0.174957, id_loss: 0.0022197\n",
      "INFO:tensorflow:Saving model, after step 8000\n",
      "INFO:tensorflow:epoch/step: 14/8001, loss: 0.180816, recons_loss: 0.179485, id_loss: 0.00133185\n",
      "INFO:tensorflow:epoch/step: 14/8101, loss: 0.181629, recons_loss: 0.177954, id_loss: 0.00367531\n",
      "INFO:tensorflow:Saving model, after step 8200\n",
      "INFO:tensorflow:epoch/step: 14/8201, loss: 0.186511, recons_loss: 0.184457, id_loss: 0.00205389\n",
      "INFO:tensorflow:TESTING -- epoch: 15, loss: 1.35786, recons_loss: 0.400888, id_loss: 0.95697\n",
      "INFO:tensorflow:epoch/step: 15/8301, loss: 0.179351, recons_loss: 0.175844, id_loss: 0.00350686\n",
      "INFO:tensorflow:Saving model, after step 8400\n",
      "INFO:tensorflow:epoch/step: 15/8401, loss: 0.185126, recons_loss: 0.179302, id_loss: 0.00582436\n",
      "INFO:tensorflow:epoch/step: 15/8501, loss: 0.179773, recons_loss: 0.175717, id_loss: 0.00405621\n",
      "INFO:tensorflow:Saving model, after step 8600\n",
      "INFO:tensorflow:epoch/step: 15/8601, loss: 0.18538, recons_loss: 0.179897, id_loss: 0.00548294\n",
      "INFO:tensorflow:epoch/step: 15/8701, loss: 0.180036, recons_loss: 0.176954, id_loss: 0.00308269\n",
      "INFO:tensorflow:Saving model, after step 8800\n",
      "INFO:tensorflow:epoch/step: 15/8801, loss: 0.181248, recons_loss: 0.178088, id_loss: 0.00316025\n",
      "INFO:tensorflow:TESTING -- epoch: 16, loss: 1.30346, recons_loss: 0.418959, id_loss: 0.884499\n",
      "INFO:tensorflow:epoch/step: 16/8901, loss: 0.174258, recons_loss: 0.17142, id_loss: 0.00283835\n",
      "INFO:tensorflow:Saving model, after step 9000\n",
      "INFO:tensorflow:epoch/step: 16/9001, loss: 0.177462, recons_loss: 0.17632, id_loss: 0.00114223\n",
      "INFO:tensorflow:epoch/step: 16/9101, loss: 0.16718, recons_loss: 0.166655, id_loss: 0.00052501\n",
      "INFO:tensorflow:Saving model, after step 9200\n",
      "INFO:tensorflow:epoch/step: 16/9201, loss: 0.178758, recons_loss: 0.173464, id_loss: 0.00529404\n",
      "INFO:tensorflow:epoch/step: 16/9301, loss: 0.180625, recons_loss: 0.177801, id_loss: 0.00282422\n",
      "INFO:tensorflow:TESTING -- epoch: 17, loss: 1.35319, recons_loss: 0.435495, id_loss: 0.917693\n",
      "INFO:tensorflow:Saving model, after step 9400\n",
      "INFO:tensorflow:epoch/step: 17/9401, loss: 0.173428, recons_loss: 0.171466, id_loss: 0.00196194\n",
      "INFO:tensorflow:epoch/step: 17/9501, loss: 0.194919, recons_loss: 0.191482, id_loss: 0.003437\n",
      "INFO:tensorflow:Saving model, after step 9600\n",
      "INFO:tensorflow:epoch/step: 17/9601, loss: 0.169093, recons_loss: 0.168166, id_loss: 0.000927611\n",
      "INFO:tensorflow:epoch/step: 17/9701, loss: 0.176011, recons_loss: 0.173144, id_loss: 0.00286685\n",
      "INFO:tensorflow:Saving model, after step 9800\n",
      "INFO:tensorflow:epoch/step: 17/9801, loss: 0.1903, recons_loss: 0.187447, id_loss: 0.00285284\n",
      "INFO:tensorflow:epoch/step: 17/9901, loss: 0.17181, recons_loss: 0.17119, id_loss: 0.000619941\n",
      "INFO:tensorflow:TESTING -- epoch: 18, loss: 1.13346, recons_loss: 0.477037, id_loss: 0.656428\n",
      "INFO:tensorflow:Best model saved after 18 epochs\n",
      "INFO:tensorflow:Saving model, after step 10000\n",
      "INFO:tensorflow:epoch/step: 18/10001, loss: 0.167089, recons_loss: 0.165452, id_loss: 0.00163626\n",
      "INFO:tensorflow:epoch/step: 18/10101, loss: 0.175775, recons_loss: 0.173342, id_loss: 0.00243288\n",
      "INFO:tensorflow:Saving model, after step 10200\n",
      "INFO:tensorflow:epoch/step: 18/10201, loss: 0.192127, recons_loss: 0.189989, id_loss: 0.00213727\n",
      "INFO:tensorflow:epoch/step: 18/10301, loss: 0.171629, recons_loss: 0.170628, id_loss: 0.00100038\n",
      "INFO:tensorflow:Saving model, after step 10400\n",
      "INFO:tensorflow:epoch/step: 18/10401, loss: 0.174061, recons_loss: 0.170577, id_loss: 0.00348411\n",
      "INFO:tensorflow:TESTING -- epoch: 19, loss: 1.19188, recons_loss: 0.477882, id_loss: 0.714\n",
      "INFO:tensorflow:epoch/step: 19/10501, loss: 0.177579, recons_loss: 0.176411, id_loss: 0.00116837\n",
      "INFO:tensorflow:Saving model, after step 10600\n",
      "INFO:tensorflow:epoch/step: 19/10601, loss: 0.183734, recons_loss: 0.181324, id_loss: 0.0024102\n",
      "INFO:tensorflow:epoch/step: 19/10701, loss: 0.18446, recons_loss: 0.179595, id_loss: 0.00486522\n",
      "INFO:tensorflow:Saving model, after step 10800\n",
      "INFO:tensorflow:epoch/step: 19/10801, loss: 0.184139, recons_loss: 0.181407, id_loss: 0.00273135\n",
      "INFO:tensorflow:epoch/step: 19/10901, loss: 0.188133, recons_loss: 0.184232, id_loss: 0.00390146\n",
      "INFO:tensorflow:Saving model, after step 11000\n",
      "INFO:tensorflow:Trained for 19 epochs\n",
      "Saved all run data to: ./saucie_models/mnist/17-09-24-runs/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('loss', 1.1918824),\n",
       "             ('recons_loss', 0.47788247),\n",
       "             ('id_loss', 0.71399993)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if verbose:\n",
    "    tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "else:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "if debug:\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "\n",
    "model = Saucie(**config)\n",
    "plot_dir = model.save_path + '/plots'\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "model.build(sess)\n",
    "\n",
    "steps_per_epoch = data.num_samples // batch_size\n",
    "num_steps = steps_per_epoch * num_epochs\n",
    "train(model, sess, data, batch_size, num_steps, thresh, patience, log_every, save_every, save_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique binary clusters: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    }
   ],
   "source": [
    "plot_folder = model.save_path + '/plots'\n",
    "\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "save_file = plot_folder + '/embedding.png'\n",
    "\n",
    "plot_ops = OrderedDict(emb=model.encoder)\n",
    "plot_ops['cluster_acts'] = tf.get_collection('id_normalized_activations')\n",
    "\n",
    "subs = np.random.choice(np.arange(len(data.data)), 5000, replace=False)\n",
    "test_feed_dict = {model.x_: data.data[subs,:],\n",
    "                  model.is_training_: False}\n",
    "\n",
    "plot_dict = sess.run(plot_ops, feed_dict=test_feed_dict)\n",
    "\n",
    "acts = plot_dict['cluster_acts'][0]\n",
    "clusts = utils.binarize(acts, thresh)\n",
    "plotting.plot_embedding2D(plot_dict['emb'], clusts, save_file, 'Bottleneck layer embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
