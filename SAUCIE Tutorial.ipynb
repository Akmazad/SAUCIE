{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAUCIE\n",
    "*Sparse Autoencoders for Unsupervised Clustering, Imputation, and Embedding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import plotting\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import saucie\n",
    "import saucie_utils as utils\n",
    "\n",
    "from collections import OrderedDict\n",
    "from saucie import Saucie\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "from saucie_utils import DataSet\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "('input_dim', 784)\n",
      "('encoder_layers', [1024, 512, 256])\n",
      "('emb_dim', 2)\n",
      "('act_fn', 'tanh')\n",
      "('d_act_fn', 'tanh')\n",
      "('use_bias', True)\n",
      "('loss_fn', 'bce')\n",
      "('opt_method', 'adam')\n",
      "('lr', 0.001)\n",
      "('batch_norm', True)\n",
      "('sparse_config', SparseLayerConfig(id_lam=[100.0, 0.0, 0.0],l1_lam=[0.0, 0.0, 0.0]))\n",
      "('save_path', './saucie_models/mnist')\n"
     ]
    }
   ],
   "source": [
    "data_path = '/home/ubuntu/SAUCIE/mnist_data.npz'\n",
    "dataset = 'mnist'\n",
    "#data = utils.load_dataset(dataset, data_path)\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "data_dict = dict(_data=mnist.train.images, _labels=mnist.train.labels, _test_data=mnist.test.images, _test_labels=mnist.test.labels)\n",
    "data = DataSet(labeled=True, **data_dict)\n",
    "\n",
    "config = saucie.default_config(dataset)\n",
    "print('\\n'.join([str(x) for x in config.items()]))\n",
    "\n",
    "model = Saucie(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TRAINING FLAGS\n",
    "batch_size = 100     # size of batch during training\n",
    "num_epochs = 20      # number of epochs to train\n",
    "patience = 5         # number of epochs to train without improvement, early stopping\n",
    "log_every = 100      # training loss logging frequency\n",
    "save_every = 200     # checkpointing frequency\n",
    "tb_graph = True      # logs graph to TensorBoard if True\n",
    "tb_summs = True      # logs summaries to TensorBoard if True\n",
    "debug = False        # enable tfdebug\n",
    "verbose = False      # will log in debug mode if True\n",
    "gpu_mem = 0.45       # percent of gpu mem to allocate\n",
    "\n",
    "# PLOTTING FLAGS\n",
    "thresh = .5          # threshold to binarize id regularized layers\n",
    "save_plots = False    # saves plots if True\n",
    "\n",
    "plot_dir = model.save_path + '/plots'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training Methods\n",
    "Edit this to change what is saved, printed, trained, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(model, sess, data, batch_size, num_steps, thresh=0.5, patience=None,\n",
    "          log_freq=100, ckpt_freq=100, save_plots=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Saucie instance to train\n",
    "        sess: tf.Session object to run all ops with\n",
    "        data: utils.DataSet object to load batches and test data from\n",
    "        batch_size: size of batches to train with\n",
    "        num_steps: number of optimizer iteration steps\n",
    "        thresh: threshold for binarization\n",
    "        patience: number of epochs of training allowed without improvement\n",
    "        log_freq: number of steps before printing training loss\n",
    "        ckpt_freq: number of steps before checkpointing model\n",
    "        save_plots: boolean determining whether or not to save plots\n",
    "    \"\"\"\n",
    "    model.epochs_trained = data.epochs_trained = model.current_epoch_.eval(sess)\n",
    "    graph = sess.graph\n",
    "    loss_tensors = model.loss_tensors_dict(graph)\n",
    "    train_ops = dict(losses=loss_tensors, opt=model.optimize)\n",
    "    test_ops = dict(losses=loss_tensors)\n",
    "    test_feed_dict = {model.x_: data.test_data, model.is_training_: False}\n",
    "    train_feed_dict = {model.x_: data.data, model.is_training_: False}\n",
    "    best_test_losses = None\n",
    "    epochs_since_improved = 0\n",
    "    current_step = model.global_step_.eval(sess)\n",
    "    id_lam = model._model_config['sparse_config'].id_lam\n",
    "    l1_lam = model._model_config['sparse_config'].l1_lam\n",
    "    cluster_layers = id_lam.nonzero()[0].tolist()\n",
    "\n",
    "    print('Saving all run data to: {}'.format(model.save_path))\n",
    "\n",
    "    if tb_graph or tb_summs: \n",
    "        train_writer = tf.summary.FileWriter(model.save_path + '/logs/train', graph=graph)\n",
    "        test_writer = tf.summary.FileWriter(model.save_path + '/logs/test', graph=graph)\n",
    "        tf.logging.debug('Saving graph to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if tb_summs:\n",
    "        loss_summs = [tf.summary.scalar(name, loss) for name, loss in loss_tensors.items() if type(loss) != list]\n",
    "        loss_summs = tf.summary.merge(loss_summs)\n",
    "        train_ops['loss_summs'] = loss_summs\n",
    "        test_ops['loss_summs'] = loss_summs\n",
    "        tf.logging.debug('Saving loss summaries to TensorBoard in {}/logs'.format(model.save_path))\n",
    "\n",
    "    if save_plots:\n",
    "        plot_folder = model.save_path + '/plots'\n",
    "        if not os.path.exists(plot_folder):\n",
    "            os.makedirs(plot_folder)\n",
    "        plot_ops = OrderedDict(emb=model.encoder)\n",
    "        plot_ops['cluster_acts'] = tf.get_collection('id_normalized_activations')\n",
    "\n",
    "    for step in range(current_step + 1, num_steps + 1):\n",
    "        batch = data.next_batch(batch_size)\n",
    "        if data.labeled:\n",
    "            batch, labels = batch\n",
    "        feed_dict = {model.x_: batch, model.is_training_: True}\n",
    "        train_dict = sess.run(train_ops, feed_dict=feed_dict)\n",
    "        train_losses = train_dict['losses']\n",
    "        if 'loss_summs' in train_dict:\n",
    "            summ = train_dict['loss_summs']\n",
    "            train_writer.add_summary(summ, step)\n",
    "        log_str = ('epoch/step: {}/{}, '.format(model.epochs_trained, step)\n",
    "                   + utils.make_dict_str(train_losses))\n",
    "        tf.logging.log_every_n(tf.logging.INFO, log_str, log_freq)\n",
    "\n",
    "        if ckpt_freq and (step % ckpt_freq) == 0:\n",
    "            tf.logging.info('Saving model, after step {}'.format(step))\n",
    "            model.save_model(sess, 'model', step=step)\n",
    "            if save_plots:\n",
    "                tf.logging.debug('Plotting middle layer embedding')\n",
    "                plot_dict = sess.run(plot_ops, feed_dict=feed_dict)\n",
    "                make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'cluster_layer-{}.png')\n",
    "\n",
    "        if model.epochs_trained != data.epochs_trained:\n",
    "            model.epochs_trained = sess.run(tf.assign(model.current_epoch_, data.epochs_trained))\n",
    "            test_dict = sess.run(test_ops, feed_dict=test_feed_dict)\n",
    "            test_losses = test_dict['losses']\n",
    "            if 'loss_summs' in test_dict:\n",
    "                summ = test_dict['loss_summs']\n",
    "                test_writer.add_summary(summ, step)\n",
    "            log_str = ('TESTING -- epoch: {}, '.format(model.epochs_trained)\n",
    "                       + utils.make_dict_str(test_losses))\n",
    "            tf.logging.info(log_str)\n",
    "            if best_test_losses is None or best_test_losses['loss'] > test_losses['loss']:\n",
    "                model.saver.save(sess, model.save_path + '/best.model')\n",
    "                tf.logging.info('Best model saved after {} epochs'.format(model.epochs_trained))\n",
    "                best_test_losses = test_losses\n",
    "                epochs_since_improved = 0\n",
    "                if save_plots:\n",
    "                    tf.logging.debug('Plotting best middle layer embedding')\n",
    "                    plot_dict = sess.run(plot_ops, feed_dict=test_feed_dict)\n",
    "                    make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, 'best-cluster_layer-{}.png')\n",
    "            else:\n",
    "                epochs_since_improved += 1\n",
    "            if patience and epochs_since_improved == patience:\n",
    "                tf.logging.info('Early stopping, test loss did not improve for {} epochs.'.format(epochs_since_improved))\n",
    "                tf.logging.info('Best test loss: epoch {}: '.format(model.epochs_trained - epochs_since_improved)\n",
    "                                + utils.make_dict_str(best_test_losses))\n",
    "                break\n",
    "\n",
    "    tf.logging.info('Trained for {} epochs'.format(model.epochs_trained))\n",
    "\n",
    "    print('Saved all run data to: {}'.format(model.save_path))\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "def make_plots(cluster_layers, id_lam, l1_lam, plot_folder, plot_dict, data, title_fmt='clust_layer-{}.png'):\n",
    "    for i, acts in enumerate(plot_dict['cluster_acts']):\n",
    "        hl_idx = cluster_layers[i]\n",
    "        save_file = plot_folder + '/emb-' + title_fmt.format(hl_idx)\n",
    "        title = 'Embedding, clustered layer-{}, id_lam/l1_lam={:5.4E}/{:5.4E}'.format(hl_idx, id_lam[hl_idx], l1_lam[hl_idx])\n",
    "        clusts = utils.binarize(acts, thresh)\n",
    "        tf.logging.debug('Top 5 activated neurons: {}'.format(acts.max(axis=1)[:5]))\n",
    "        tf.logging.debug('Mean max activation: {}'.format(acts.max(axis=1).mean()))\n",
    "        tf.logging.debug('Bottom 5 max activated neurons: {}'.format(acts.max(axis=1)[-5:]))\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], clusts, save_file, title)\n",
    "        if '_colnames' in data.__dict__:\n",
    "            save_file = plot_folder + '/heatmap-' + title_fmt.format(hl_idx)\n",
    "            plotting.plot_cluster_heatmap(data.test_data, clusts, data._colnames, data._markers, save_file)\n",
    "    if cluster_layers == []:\n",
    "        plotting.plot_embedding2D(plot_dict['emb'], np.zeros(len(plot_dict['emb'])), plot_folder + '/emb.png','Embedding, no clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Mul' Op has type float32 that does not match type float64 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    491\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    550\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'Tensor(\"loss/id_reg/Neg:0\", shape=(), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-07f9128b88b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgpu_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPUOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SAUCIE/saucie.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Built SAUCIE decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Built SAUCIE loss ops and optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SAUCIE/saucie_utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SAUCIE/saucie.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0mact_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACT_FNS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_acts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mact_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'normalized_act-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                     \u001b[0mid_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'id_loss_layer_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id_penalties'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m                     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id_normalized_activations'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mid_losses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id_penalties'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SAUCIE/saucie_utils.py\u001b[0m in \u001b[0;36mid_penalty\u001b[0;34m(act, lam, name)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# information dimension regularization penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mid_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m   \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    524\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 526\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Mul' Op has type float32 that does not match type float64 of argument 'x'."
     ]
    }
   ],
   "source": [
    "if verbose:\n",
    "    tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "else:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "if debug:\n",
    "    sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "    sess.add_tensor_filter('has_inf_or_nan', tf_debug.has_inf_or_nan)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_mem)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "model.build(sess)\n",
    "\n",
    "steps_per_epoch = data.num_samples // batch_size\n",
    "num_steps = steps_per_epoch * num_epochs\n",
    "train(model, sess, data, batch_size, num_steps, thresh, patience, log_every, save_every, save_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "navigate_menu": false,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
